{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SeongGwangJu/SeongGwangJu/blob/main/%EB%A7%8C%EB%93%A4%EB%A9%B4%EC%84%9C_%EB%B0%B0%EC%9A%B0%EB%8A%94_AI_%EC%84%9C%EB%B9%84%EC%8A%A4_%EC%8B%A4%EC%8A%B52.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 패키지 설치\n",
        "Langchain, Google-genai 패키지를 설치합니다."
      ],
      "metadata": {
        "id": "1GsT6TenzG6M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uug9_l2UzAYa",
        "outputId": "f141a50c-d4b8-4da1-e15d-a8e496767906"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m76.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.5/310.5 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m92.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.9/131.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/208.0 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m129.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q chromadb google-generativeai langchain-google-genai langchain_community pypdf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### API 키 등록\n",
        "Gemini API를 사용하기 위해서 Google_API_Key를 불러옵니다.\n",
        "Colab 왼쪽 패널의 `보안 비밀`, `Gemini API 키`, `Google AI Studio에서 키 가져오기`를 선택해 키를 불러옵니다."
      ],
      "metadata": {
        "id": "WKDE2d5XzMSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "\n",
        "# Secrets에 저장된 값을 가져옵니다.\n",
        "my_api_key = userdata.get('GOOGLE_API_KEY')\n",
        "\n",
        "# os.getenv()를 사용하는 라이브러리와의 호환을 위해 os.environ에 설정해줍니다.\n",
        "os.environ['GOOGLE_API_KEY'] = my_api_key\n",
        "\n",
        "# 이제 os.getenv()로 값을 읽을 수 있습니다.\n",
        "retrieved_key = os.getenv('GOOGLE_API_KEY')\n",
        "print(\"키를 성공적으로 불러왔습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EDa4ZVRzLOn",
        "outputId": "c5e5abad-87eb-48c6-db46-d0cbc453afac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "키를 성공적으로 불러왔습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RAG : Retrieval-Augmented Generation\n",
        "\n",
        "RAG는 모델 내부의 지식에만 의존하지 않고 외부의 최신 또는\n",
        "전문적인 정보를 실시간으로 검색하여 그 결과를 바탕으로 답변을 생성하는 기법입니다.\n",
        "\n",
        "PDF 파일에서 유사도 검색을 통해 RAG를 적용해보겠습니다."
      ],
      "metadata": {
        "id": "mAFnJo-uzUts"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Colab에 파일 업로드하기"
      ],
      "metadata": {
        "id": "_dErIy1zzYjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "# 업로드된 파일 이름 가져오기\n",
        "file_name = next(iter(uploaded))\n",
        "\n",
        "# 파일 내용(바이트)을 변수에 저장\n",
        "file_content = uploaded[file_name]\n",
        "\n",
        "print(f'파일 이름: {file_name}')\n",
        "print(f'파일 크기: {len(file_content)} 바이트')\n",
        "print(f'파일 내용(일부): {file_content[:50]}...')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "9K3b4PV_zV0k",
        "outputId": "039f7064-b175-44ea-94aa-86aff92e6049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-a233b368-a192-4b16-9824-c99c0d8c80c2\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-a233b368-a192-4b16-9824-c99c0d8c80c2\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving 18859_2.pdf to 18859_2.pdf\n",
            "파일 이름: 18859_2.pdf\n",
            "파일 크기: 3191319 바이트\n",
            "파일 내용(일부): b'%PDF-1.6\\r%\\xe2\\xe3\\xcf\\xd3\\r\\n2667 0 obj\\r<</Linearized 1/L 31913'...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import files, userdata\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma"
      ],
      "metadata": {
        "id": "HeQKDkeG0O8g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PyPDFLoader**는 PDF 문서를 로드하는 역할을 합니다. 이 로더를 사용하면 PDF 파일의 텍스트와 메타데이터를 LangChain이 처리할 수 있는 Document 객체로 변환할 수 있습니다.\n",
        "\n",
        "**RecursiveCharacterTextSplitter**는 긴 문서를 작은 텍스트 덩어리(chunk)로 나누는 역할을 합니다.  LLM은 한 번에 처리할 수 있는 텍스트 양에 한계가 있어, 이 스플리터를 사용해 문서를 효과적으로 분할해야 합니다.\n",
        "\n",
        "**Chroma**는 텍스트 임베딩을 저장하고 검색하는 벡터 데이터베이스입니다. PyPDFLoader로 로드하고 RecursiveCharacterTextSplitter로 분할된 텍스트 청크들을 임베딩으로 변환한 후, 이 벡터 데이터베이스에 저장하여 나중에 사용자의 질문과 관련된 문서를 빠르게 찾아낼 수 있습니다."
      ],
      "metadata": {
        "id": "m0wxz9G619z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pdf_file_path = list(uploaded.keys())[0]\n",
        "print(f\"'{pdf_file_path}' 파일이 업로드되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5C72flOhzvcf",
        "outputId": "c4934b86-0ba2-4693-a713-8a558d527472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'18859_2.pdf' 파일이 업로드되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector DB 만들기\n",
        "RAG를 사용하기 전, Vector DB를 먼저 구축해야 합니다.\n",
        "\n",
        "Vector DB는 준비된 파일로부터 텍스트를 로드, 분할, 임베딩 과정을 거쳐서 생성됩니다.\n",
        "\n",
        "`Text load` -> `Text split` -> `Text embedding`"
      ],
      "metadata": {
        "id": "e3ZNIMr6TpYc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PDF 파일 로드:\n",
        "`PyPDFLoader`로 PDF 파일을 준비하고, LangChain이 사용할 수 있는 형식으로 변환합니다.\n",
        "\n",
        "### 텍스트 분할:\n",
        "`RecursiveCharacterTextSplitter`를 사용해 긴 문서를 작은 텍스트 조각들로 나눕니다.\n",
        "\n",
        "`chunk_size=1000`은 각 조각의 크기를 약 1,000자로 정합니다. LLM은 한 번에 처리할 수 있는 텍스트 양이 제한되어 있어 이렇게 나누는 것이 필수적입니다.\n",
        "\n",
        "`chunk_overlap=200`은 앞뒤 조각이 200자 정도 겹치게 하여, 문맥이 끊기지 않도록 도와줍니다.\n",
        "\n",
        "### 결과 확인:\n",
        "`text_splitter.split_documents(documents)`는 문서를 나누는 과정입니다."
      ],
      "metadata": {
        "id": "K4-JCJ0j3m-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PDF 로드 및 텍스트 분할을 시작합니다.\n",
        "print(\"PDF 로드 및 텍스트 분할\")\n",
        "\n",
        "# PyPDFLoader를 사용하여 지정된 경로의 PDF 파일을 로드할 준비를 합니다.\n",
        "loader = PyPDFLoader(pdf_file_path)\n",
        "\n",
        "# PDF 파일의 모든 페이지를 불러와서 'documents' 변수에 저장합니다.\n",
        "# 각 페이지는 LangChain의 Document 객체가 됩니다.\n",
        "documents = loader.load()\n",
        "\n",
        "# 텍스트를 나눌 기준을 정의하는 RecursiveCharacterTextSplitter를 생성합니다.\n",
        "# chunk_size는 텍스트 덩어리의 최대 크기를, chunk_overlap은 덩어리 간의 겹치는 부분을 지정합니다.\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200) # ⭐ 파라미터를 바꾸어서 테스트 해보세요! 결과는 바로 아래 코드 (print(texts[11])) 에서 청크 사이즈를 확인할 수 있습니다.\n",
        "\n",
        "# 로드된 문서를 위에서 정의한 기준으로 작은 텍스트 덩어리(청크)로 분할합니다.\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# 분할된 텍스트 덩어리의 총 개수를 출력하여 확인합니다.\n",
        "print(f\"총 {len(texts)}개의 텍스트 청크로 분할되었습니다.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQGYDpJG11by",
        "outputId": "66392c06-42cc-4d47-a53e-9b0f8f24f633"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF 로드 및 텍스트 분할\n",
            "총 17개의 텍스트 청크로 분할되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "아래와 같이, 11번째 청크를 확인할 수 있습니다."
      ],
      "metadata": {
        "id": "16xcEteh4rd4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(texts[11]))\n",
        "print(texts[11])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yQfrlSAL2Fyr",
        "outputId": "68cd1808-cfc6-4394-8a22-baee7d009bdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'langchain_core.documents.base.Document'>\n",
            "page_content='Ⅱ. 2025~26년 국내경제 전망\n",
            "11\n",
            "1. 대외여건에 대한 주요 전제\n",
            "2025~26년 세계경제는 미국 관세인상 등으로 낮은 성장세에 머무를 것으로 전제\n",
            "최근 IMF는 금년과 내년의 세계경제 성장률을 각각 3.0%, 3.1%로 전망하였으며, 이는 \n",
            "코로나19 위기 이전(2011~19년)의 평균 성장률(3.5%)보다 낮은 수준임.\n",
            "최근 WSTS는 2025년 메모리반도체 매출액 증가율을 기존(2025년 상반기 KDI 경제\n",
            "전망) 전제(13.4%)보다 높은 17.1%로 전망\n",
            "미국 관세율은 현재 정해진 수준이 향후에도 유지될 것으로 전제하였으며, 이에 따라 \n",
            "우리 상품에 대한 평균 관세율은 기존 전제(14.1%)와 유사한 14.5%로 전제\n",
            "╺ 최근 발표된 반도체 관세는 세부 사항이 불명확하여, 이번 전망에는 반영되지 않음.\n",
            "원유 도입단가(두바이유 기준)는 수요 부진에 주로 기인하여 2024년의 배럴당 80달러\n",
            "에서 2025년 71달러, 2026년 67달러로 하락할 것으로 전제\n",
            "다만, 지정학적 위험　확대에 따른 유가 상승을 반영하여 기존 전제(69달러, 66달러)\n",
            "보다는 소폭 상향 조정\n",
            "실질실효환율로 평가한 원화가치는 최근 수준에서 큰 변동이 없을 것으로 전제\n",
            "글로벌 메모리반도체 매출액 증가율 전제 국제유가 전제\n",
            "  주: 기존 전제는 2025년 상반기(5월) KDI 경제전망 전제이며, 국제유가는 두바이유 기준임.\n",
            "자료: WSTS; 한국석유공사; KDI 자체 전망.' metadata={'producer': 'Adobe Acrobat (64-bit) 25.1.20577', 'creator': 'Adobe Acrobat (64-bit) 25.1.20577', 'creationdate': '2025-08-12T17:23:03+09:00', 'author': 'master', 'moddate': '2025-08-12T17:32:06+09:00', 'source': '18859_2.pdf', 'total_pages': 20, 'page': 15, 'page_label': '16'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제, `GoogleGenerativeAIEmbeddings`를 활용해 임베딩을 생성합니다."
      ],
      "metadata": {
        "id": "bruoHH7MUM-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "\n",
        "# 임베딩 및 벡터 데이터베이스 생성\n",
        "print(\"텍스트 임베딩 및 벡터 데이터베이스 생성 중...\")\n",
        "\n",
        "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "vectordb = Chroma.from_documents(texts, embeddings)\n",
        "\n",
        "print(\"임베딩 및 벡터 데이터베이스 생성되었습니다\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ClGbW_ys4wit",
        "outputId": "0e85d39b-3046-4779-c1a8-ca9a79e794c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "텍스트 임베딩 및 벡터 데이터베이스 생성 중...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retriver(검색기) 설정\n",
        "--- **기본 유사도 검색(Similarity Search) 설정** ---\n",
        "\n",
        "이 방식은 가장 직관적인 검색 방법으로, 사용자의 질문과 의미적으로\n",
        "'가장 가까운(가장 유사한)' 문서 조각을 순서대로 찾아옵니다.\n",
        "\n",
        "* search_type=\"similarity\": 검색 유형을 유사도(기본값)로 설정합니다.\n",
        "* search_kwargs={'k': 4}:\n",
        "   - k=4: 질문과 가장 유사한 순서대로 문서 조각 4개를 찾아 LLM에게 전달합니다.\n",
        "\n",
        "```python\n",
        "retriever = vectordb.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={'k': 4}\n",
        ")\n",
        "```\n",
        "\n",
        "참고: as_retriever()에 아무 옵션을 주지 않으면 이 설정과 동일하게 작동합니다.\n",
        "```python\n",
        "retriever = vectordb.as_retriever()\n",
        "```\n",
        "--- **MMR(Maximal Marginal Relevance) 검색기 설정** ---\n",
        "\n",
        "단순 유사도 검색의 단점을 보완하기 위해 MMR 방식을 사용합니다.\n",
        "MMR은 질문과의 '유사도'와 이미 선택된 문서들과의 '다양성'을 함께 고려하여,\n",
        "목차나 거의 동일한 내용의 문서 조각이 중복으로 검색 결과에 포함되는 것을 방지합니다.\n",
        "\n",
        "* search_type=\"mmr\": 검색 알고리즘을 MMR로 지정합니다.\n",
        "* search_kwargs={'k': 5, 'fetch_k': 20}:\n",
        "   - fetch_k=20: 먼저 질문과 유사도가 높은 문서 후보 20개를 가져옵니다.\n",
        "   - k=5: 가져온 후보 20개 중에서, 유사도와 다양성을 함께 평가하여 최종 5개를 선택해 LLM에게 전달합니다."
      ],
      "metadata": {
        "id": "M_8RStmCVRjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectordb.as_retriever(\n",
        "    search_type=\"mmr\",                      # ⭐ 알고리즘을 바꾸어서 테스트 해보세요!\n",
        "    search_kwargs={'k': 5, 'fetch_k': 20}   # ⭐ 파라미터를 바꾸어서 테스트 해보세요!\n",
        ")"
      ],
      "metadata": {
        "id": "4ggKieFdR7aR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retriever(검색기)에 사용자 질의를 던져 유사한 문서를 확인할 수 있습니다.\n",
        "\n",
        "이때, 유사한 문서를 가져오는 규칙은 정의한 알고리즘(`search_type`)에 따라 달라집니다."
      ],
      "metadata": {
        "id": "Qkm5cGAxXKqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"2025~26년 국내경제 전망에 대해 알려주세요\" # ⭐ 질문을 바꾸어서 테스트 해보세요!\n",
        "retrieved_docs = retriever.invoke(question)\n",
        "\n",
        "print(\"--- 검색된 문서 조각 (Retrieved Chunks) ---\")   # 검색된 문서 조각을 확인할 수 있습니다.\n",
        "for i, doc in enumerate(retrieved_docs):               # 문서 조각은 청크로 나뉘어서 출력됩니다. 이 결과가 프롬프트에 들어가게 됩니다.\n",
        "    print(f\"--- CHUNK {i+1} (Page: {doc.metadata.get('page', 'N/A')}) ---\")\n",
        "    print(doc.page_content)\n",
        "    print(\"-\" * 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py3-uhqjXGa8",
        "outputId": "bb8cbe22-4bd0-42cc-91bd-41eb045084e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- 검색된 문서 조각 (Retrieved Chunks) ---\n",
            "--- CHUNK 1 (Page: 13) ---\n",
            "Ⅱ\n",
            "2025~26년 국내경제 전망\n",
            "1. 대외여건에 대한 주요 전제\n",
            "2. 2025~26년 국내경제 전망\n",
            "3. 전망의 위험요인\n",
            "--------------------------------------------------\n",
            "--- CHUNK 2 (Page: 15) ---\n",
            "Ⅱ. 2025~26년 국내경제 전망\n",
            "11\n",
            "1. 대외여건에 대한 주요 전제\n",
            "2025~26년 세계경제는 미국 관세인상 등으로 낮은 성장세에 머무를 것으로 전제\n",
            "최근 IMF는 금년과 내년의 세계경제 성장률을 각각 3.0%, 3.1%로 전망하였으며, 이는 \n",
            "코로나19 위기 이전(2011~19년)의 평균 성장률(3.5%)보다 낮은 수준임.\n",
            "--------------------------------------------------\n",
            "--- CHUNK 3 (Page: 19) ---\n",
            "Ⅱ. 2025~26년 국내경제 전망\n",
            "15\n",
            "2025~26년 경제전망\n",
            "(전년동기대비, %, %p, 억달러, 만명)\n",
            "2024p 2025p 2026 2025 \n",
            "수정폭2)\n",
            "2026 \n",
            "수정폭2)\n",
            "연간p 상반기p 하반기 연간 연간\n",
            "국내총생산 2.0 0.2 1.3 0.8 1.6 0.0 0.0 \n",
            "총소비 1.4 1.2 2.0 1.6 1.7 0.2 0.0 \n",
            " 민간소비 1.1 0.7 1.8 1.3 1.5 0.2 -0.1\n",
            "총고정투자 -0.8 -4.0 -1.4 -2.7 2.2 -1.8 0.2 \n",
            " 설비투자 1.7 4.8 -1.0 1.8 1.6 0.1 0.0 \n",
            " 건설투자 -3.3 -12.4 -3.8 -8.1 2.6 -3.9 0.2 \n",
            " 지식재산생산물투자 1.2 1.3 2.9 2.2 2.1 0.2 0.2 \n",
            "총수출(물량) 6.8 2.8 1.4 2.1 0.6 1.8 -0.2\n",
            " 상품수출(물량) 6.4 1.6 0.9 1.2 0.2 1.6 -0.3\n",
            "총수입(물량) 2.5 3.1 0.9 2.0 1.2 1.2 -0.2\n",
            " 상품수입(물량) 1.3 1.8 0.3 1.0 0.7 1.0 -0.2\n",
            "경상수지 990 494 568 1,062 912 142 108 \n",
            " 상품수지 1,001 520 552 1,072 935 120 87 \n",
            " 수출(금액) 6,962 3,388 3,487 6,874 6,742 174 160 \n",
            " (증가율) 8.2 -0.3 -2.1 -1.3 -1.9 2.5 -0.1\n",
            " 수입(금액) 5,961 2,868 2,935 5,803 5,807 56 73\n",
            " (증가율) -1.6 -2.5 -2.8 -2.6 0.1 1.0 0.3\n",
            " 서비스수지, \n",
            "본원⋅이전소득수지 -11 -26 17 -9 -23 24 20 \n",
            "소비자물가 2.3 2.1 1.9 2.0 1.8 0.3 0.0 \n",
            "근원물가 2.2 1.9 1.9 1.9 1.9 0.1 0.0 \n",
            "취업자 수(증감) 16 18 13 15 11 6 4 \n",
            "실업률 2.8 3.1 2.6 2.9 2.9 -0.1 -0.1\n",
            "(계절조정) 2.8 2.9 \n",
            "주: 1) p는 잠정치임.\n",
            "--------------------------------------------------\n",
            "--- CHUNK 4 (Page: 15) ---\n",
            "Ⅱ. 2025~26년 국내경제 전망\n",
            "11\n",
            "1. 대외여건에 대한 주요 전제\n",
            "2025~26년 세계경제는 미국 관세인상 등으로 낮은 성장세에 머무를 것으로 전제\n",
            "최근 IMF는 금년과 내년의 세계경제 성장률을 각각 3.0%, 3.1%로 전망하였으며, 이는 \n",
            "코로나19 위기 이전(2011~19년)의 평균 성장률(3.5%)보다 낮은 수준임.\n",
            "최근 WSTS는 2025년 메모리반도체 매출액 증가율을 기존(2025년 상반기 KDI 경제\n",
            "전망) 전제(13.4%)보다 높은 17.1%로 전망\n",
            "미국 관세율은 현재 정해진 수준이 향후에도 유지될 것으로 전제하였으며, 이에 따라 \n",
            "우리 상품에 대한 평균 관세율은 기존 전제(14.1%)와 유사한 14.5%로 전제\n",
            "╺ 최근 발표된 반도체 관세는 세부 사항이 불명확하여, 이번 전망에는 반영되지 않음.\n",
            "원유 도입단가(두바이유 기준)는 수요 부진에 주로 기인하여 2024년의 배럴당 80달러\n",
            "에서 2025년 71달러, 2026년 67달러로 하락할 것으로 전제\n",
            "다만, 지정학적 위험　확대에 따른 유가 상승을 반영하여 기존 전제(69달러, 66달러)\n",
            "보다는 소폭 상향 조정\n",
            "실질실효환율로 평가한 원화가치는 최근 수준에서 큰 변동이 없을 것으로 전제\n",
            "글로벌 메모리반도체 매출액 증가율 전제 국제유가 전제\n",
            "  주: 기존 전제는 2025년 상반기(5월) KDI 경제전망 전제이며, 국제유가는 두바이유 기준임.\n",
            "자료: WSTS; 한국석유공사; KDI 자체 전망.\n",
            "--------------------------------------------------\n",
            "--- CHUNK 5 (Page: 0) ---\n",
            "2025년 8월\n",
            "kdi Economic outlook \n",
            "kdi 경제전망| 수정\n",
            "제42권 제3호 / Vol.42 No.3\n",
            "| UPDATE\n",
            "--------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "이제, 프롬프트 템플릿을 정의하고 chain을 구축합니다."
      ],
      "metadata": {
        "id": "-FHEiaeUWlg7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 프롬프트 템플릿 정의\n",
        "template = \"\"\"\n",
        "당신은 주어진 문서를 바탕으로 사용자의 질문에 답하는 유용한 AI 어시스턴트입니다.\n",
        "검색된 참고문서를 먼저 알려주고,\n",
        "참고 문서를 참고하여 사용자 질문에 답변해주세요.\n",
        "\n",
        "참고 문서:\n",
        "{context}\n",
        "\n",
        "사용자 질문:\n",
        "{query}\n",
        "\n",
        "답변은 오직 제공된 참고 문서에 기반해야 합니다.\n",
        "\"\"\"\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# LLM 모델 정의\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash-lite\", temperature=0)\n",
        "\n",
        "# 체인 구축: (검색기 | 프롬프트) | LLM\n",
        "# RunnablePassthrough.assign()은 검색 결과를 'context' 변수로 전달합니다.\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"query\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        ")"
      ],
      "metadata": {
        "id": "r7l8pGcJN79u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "사용자의 질문을 정의하고, chain을 invoke 합니다."
      ],
      "metadata": {
        "id": "yIVPDyQkW4Y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "question = \"2025~26년 국내경제 전망에 대해 알려주세요\"\n",
        "response = rag_chain.invoke(question)\n",
        "\n",
        "print(f\"사용자 질문: {question}\")\n",
        "print(\"---\")\n",
        "print(f\"답변: \\n{response.content}\")\n",
        "print(\"--------------------\")\n"
      ],
      "metadata": {
        "id": "rXqq5vzTWyop"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}